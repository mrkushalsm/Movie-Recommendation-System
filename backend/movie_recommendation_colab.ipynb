{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd56bfef",
   "metadata": {},
   "source": [
    "## üöÄ Quick Start Guide\n",
    "\n",
    "**First time setup:**\n",
    "1. Run all cells in order (Runtime ‚Üí Run all)\n",
    "2. Enter your API keys when prompted\n",
    "3. Wait for all dependencies to install (~2 minutes)\n",
    "\n",
    "**If you see errors:**\n",
    "- `RecursionError`: Go to Runtime ‚Üí Restart Runtime, then run all cells\n",
    "- `API key error`: Double-check your TMDb API key is correct\n",
    "- `0 results`: Your API key might have quota limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9970bf4",
   "metadata": {},
   "source": [
    "# üé¨ Advanced Movie Recommendation System with RAG\n",
    "\n",
    "**LangGraph-based intelligent movie recommendations using:**\n",
    "- üß† **Gemini 2.0 Flash** for query analysis\n",
    "- üîç **Hybrid RAG** (FAISS + BM25)\n",
    "- üéØ **Multi-strategy TMDb search**\n",
    "- ‚≠ê **Intelligent re-ranking**\n",
    "- üìö **Wikipedia enrichment**\n",
    "- üíæ **Dynamic database growth**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46278468",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291803f",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Troubleshooting Common Errors\n",
    "\n",
    "**RecursionError:**\n",
    "- Go to `Runtime` ‚Üí `Restart Runtime` and run all cells from the beginning\n",
    "- Or run the emergency fix cell below\n",
    "\n",
    "**401 Unauthorized (TMDb API):**\n",
    "- You entered the API key incorrectly\n",
    "- Re-run cell 2 with the correct key\n",
    "\n",
    "**0 results from searches:**\n",
    "- Your API key might have quota limits\n",
    "- Try a different API key\n",
    "- Check if you can access TMDb in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Emergency Fix: Run this if you see RecursionError\n",
    "# This resets the socket module to its original state\n",
    "\n",
    "import socket\n",
    "import importlib\n",
    "\n",
    "# Reset socket module\n",
    "if hasattr(socket, '_original_getaddrinfo'):\n",
    "    socket.getaddrinfo = socket._original_getaddrinfo\n",
    "    delattr(socket, '_original_getaddrinfo')\n",
    "    print(\"‚úÖ Socket module reset! Now run cell 4 again.\")\n",
    "else:\n",
    "    print(\"‚úÖ Socket module is already in original state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5689e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-google-genai langgraph langchain-core\n",
    "!pip install -q faiss-cpu sentence-transformers\n",
    "!pip install -q rank-bm25 requests wikipedia-api\n",
    "!pip install -q python-dotenv numpy\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d573620",
   "metadata": {},
   "source": [
    "## 2. Configure API Keys\n",
    "\n",
    "### üîê Recommended: Use Colab Secrets (Most Secure)\n",
    "\n",
    "1. Click the **üîë key icon** in the left sidebar\n",
    "2. Click **\"Add a new secret\"**\n",
    "3. Add two secrets:\n",
    "4. Toggle **\"Notebook access\"** ON for both secrets\n",
    "5. Run the cell below\n",
    "\n",
    "### üìù Alternative: Manual Input (Fallback)\n",
    "\n",
    "If you don't set up secrets, the cell will prompt you to enter the keys manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Method 1: Use Colab Secrets (Recommended)\n",
    "# Go to the üîë key icon in the left sidebar ‚Üí Add secrets:\n",
    "# - Name: TMDB_API_KEY, Value: your TMDb API key\n",
    "# - Name: GOOGLE_API_KEY, Value: your Google API key\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    TMDB_API_KEY = userdata.get('TMDB_API_KEY')\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "    print(\"‚úÖ Using Colab Secrets (secure method)\")\n",
    "except:\n",
    "    # Method 2: Manual input (fallback if secrets not configured)\n",
    "    from getpass import getpass\n",
    "    print(\"‚ö†Ô∏è  Colab Secrets not found. Using manual input.\")\n",
    "    print(\"   Tip: Store secrets securely using the üîë icon in the left sidebar!\")\n",
    "    \n",
    "    TMDB_API_KEY = getpass(\"Enter your TMDb API Key (just the key, no 'TMDB_API_KEY='): \")\n",
    "    GOOGLE_API_KEY = getpass(\"Enter your Google API Key (just the key, no 'GOOGLE_API_KEY='): \")\n",
    "    \n",
    "    # Clean up common mistakes\n",
    "    TMDB_API_KEY = TMDB_API_KEY.strip()\n",
    "    if '=' in TMDB_API_KEY:\n",
    "        TMDB_API_KEY = TMDB_API_KEY.split('=', 1)[1].strip()\n",
    "    \n",
    "    GOOGLE_API_KEY = GOOGLE_API_KEY.strip()\n",
    "    if '=' in GOOGLE_API_KEY:\n",
    "        GOOGLE_API_KEY = GOOGLE_API_KEY.split('=', 1)[1].strip()\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['TMDB_API_KEY'] = TMDB_API_KEY\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
    "\n",
    "print(\"‚úÖ API keys configured!\")\n",
    "print(f\"   TMDb key: {TMDB_API_KEY[:10]}...\")\n",
    "print(f\"   Google key: {GOOGLE_API_KEY[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9af48d",
   "metadata": {},
   "source": [
    "## 3. Configuration Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb21d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration settings.\"\"\"\n",
    "    TMDB_API_KEY = os.getenv('TMDB_API_KEY')\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    \n",
    "    # Embedding model\n",
    "    EMBEDDING_MODEL = 'sentence-transformers/paraphrase-MiniLM-L3-v2'\n",
    "    EMBEDDING_DIM = 384\n",
    "    \n",
    "    # Storage paths (in Colab)\n",
    "    FAISS_INDEX_PATH = '/content/faiss_index.bin'\n",
    "    FAISS_MOVIES_PATH = '/content/faiss_movies.pkl'\n",
    "    BM25_INDEX_PATH = '/content/bm25_index.pkl'\n",
    "    \n",
    "    # Re-ranking weights\n",
    "    SEMANTIC_WEIGHT = 0.25\n",
    "    GENRE_WEIGHT = 0.20\n",
    "    RATING_WEIGHT = 0.20\n",
    "    RECENCY_WEIGHT = 0.15\n",
    "    POPULARITY_WEIGHT = 0.10\n",
    "    \n",
    "    MIN_RATING_COUNT = 100\n",
    "\n",
    "config = Config()\n",
    "print(\"‚úÖ Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca8fa46",
   "metadata": {},
   "source": [
    "## 4. TMDb Client (with IPv4 Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829366da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import socket\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Force IPv4 for TMDb API (safe for re-runs)\n",
    "# Store original function only once using a private attribute\n",
    "if not hasattr(socket, '_original_getaddrinfo'):\n",
    "    socket._original_getaddrinfo = socket.getaddrinfo\n",
    "\n",
    "def ipv4_only_getaddrinfo(*args, **kwargs):\n",
    "    \"\"\"Filter IPv6 addresses to force IPv4 connections.\"\"\"\n",
    "    responses = socket._original_getaddrinfo(*args, **kwargs)\n",
    "    return [response for response in responses if response[0] == socket.AF_INET]\n",
    "\n",
    "# Only apply if not already applied\n",
    "if socket.getaddrinfo != ipv4_only_getaddrinfo:\n",
    "    socket.getaddrinfo = ipv4_only_getaddrinfo\n",
    "    print(\"‚úÖ IPv4-only mode enabled for TMDb API\")\n",
    "\n",
    "class TMDbClient:\n",
    "    \"\"\"TMDb API client with IPv4 fix.\"\"\"\n",
    "    BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def _make_request(self, endpoint: str, params: Dict = None) -> Dict:\n",
    "        params = params or {}\n",
    "        params[\"api_key\"] = self.api_key\n",
    "        \n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                url = f\"{self.BASE_URL}{endpoint}\"\n",
    "                response = self.session.get(url, params=params, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                \n",
    "                # Debug: Show what we got\n",
    "                if endpoint == \"/search/movie\" and \"results\" in data:\n",
    "                    result_count = len(data.get(\"results\", []))\n",
    "                    if result_count == 0:\n",
    "                        print(f\"    ‚ö† API returned 0 results for: {params.get('query')}\")\n",
    "                \n",
    "                return data\n",
    "            except requests.exceptions.ConnectionError as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Connection error, retrying... ({attempt + 1}/{max_retries})\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"‚ùå TMDb API failed after {max_retries} attempts: {e}\")\n",
    "                    return {}\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"‚ùå TMDb API error: {e}\")\n",
    "                return {}\n",
    "        return {}\n",
    "    \n",
    "    def search_movies(self, query: str, page: int = 1) -> Dict:\n",
    "        return self._make_request(\"/search/movie\", {\"query\": query, \"page\": page})\n",
    "    \n",
    "    def get_genres(self) -> Dict:\n",
    "        return self._make_request(\"/genre/movie/list\")\n",
    "    \n",
    "    def discover_movies(self, **filters) -> Dict:\n",
    "        params = {\n",
    "            \"sort_by\": filters.get(\"sort_by\", \"popularity.desc\"),\n",
    "            \"include_adult\": \"false\",\n",
    "            \"vote_count.gte\": config.MIN_RATING_COUNT,\n",
    "        }\n",
    "        params.update({k: v for k, v in filters.items() if v is not None})\n",
    "        return self._make_request(\"/discover/movie\", params)\n",
    "\n",
    "tmdb_client = TMDbClient(config.TMDB_API_KEY)\n",
    "print(\"‚úÖ TMDb client initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96b874",
   "metadata": {},
   "source": [
    "## 5. Test TMDb Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TMDb API with simple queries\n",
    "print(\"üß™ Testing TMDb API...\\n\")\n",
    "\n",
    "# Test 1: Simple search\n",
    "test1 = tmdb_client.search_movies(\"inception\")\n",
    "if test1.get('results'):\n",
    "    print(f\"‚úÖ Test 1 PASSED: Found {len(test1['results'])} results for 'inception'\")\n",
    "    print(f\"   Example: {test1['results'][0]['title']}\")\n",
    "else:\n",
    "    print(f\"‚ùå Test 1 FAILED: No results for 'inception'\")\n",
    "    print(f\"   Response: {test1}\")\n",
    "\n",
    "# Test 2: Another simple search\n",
    "test2 = tmdb_client.search_movies(\"war\")\n",
    "if test2.get('results'):\n",
    "    print(f\"‚úÖ Test 2 PASSED: Found {len(test2['results'])} results for 'war'\")\n",
    "else:\n",
    "    print(f\"‚ùå Test 2 FAILED: No results for 'war'\")\n",
    "\n",
    "# Test 3: Get genres\n",
    "test3 = tmdb_client.get_genres()\n",
    "if test3.get('genres'):\n",
    "    print(f\"‚úÖ Test 3 PASSED: Got {len(test3['genres'])} genres\")\n",
    "else:\n",
    "    print(f\"‚ùå Test 3 FAILED: Could not get genres\")\n",
    "\n",
    "if not test1.get('results'):\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: TMDb API is not returning results!\")\n",
    "    print(\"   Possible issues:\")\n",
    "    print(\"   1. Invalid API key\")\n",
    "    print(\"   2. API key quota exceeded\")\n",
    "    print(\"   3. Network/firewall blocking TMDb\")\n",
    "    print(f\"\\n   Your API key: {config.TMDB_API_KEY[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f68a36",
   "metadata": {},
   "source": [
    "## 6. Vector Store & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Tuple\n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str):\n",
    "        print(f\"Loading embedding model: {model_name}...\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.dimension = self.model.get_sentence_embedding_dimension()\n",
    "        print(f\"‚úÖ Model loaded! Dimension: {self.dimension}\")\n",
    "    \n",
    "    def encode(self, texts: List[str]) -> np.ndarray:\n",
    "        return self.model.encode(texts, show_progress_bar=False)\n",
    "\n",
    "class FAISSVectorStore:\n",
    "    def __init__(self, embedding_manager: EmbeddingManager):\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.dimension = embedding_manager.dimension\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)  # Inner product for cosine similarity\n",
    "        self.movies = []\n",
    "    \n",
    "    def add_movie(self, movie: Dict):\n",
    "        text = self._create_movie_text(movie)\n",
    "        embedding = self.embedding_manager.encode([text])[0]\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        faiss.normalize_L2(embedding.reshape(1, -1))\n",
    "        \n",
    "        self.index.add(embedding.reshape(1, -1))\n",
    "        self.movies.append(movie)\n",
    "    \n",
    "    def _create_movie_text(self, movie: Dict) -> str:\n",
    "        components = []\n",
    "        if movie.get(\"title\"):\n",
    "            components.append(movie[\"title\"])\n",
    "        \n",
    "        genres = movie.get(\"genres\", [])\n",
    "        genre_names = [g.get(\"name\", g) if isinstance(g, dict) else str(g) for g in genres]\n",
    "        components.extend(genre_names)\n",
    "        \n",
    "        if movie.get(\"overview\"):\n",
    "            components.append(movie[\"overview\"])\n",
    "        \n",
    "        return \" \".join(components)\n",
    "    \n",
    "    def search(self, query: str, k: int = 20) -> List[Tuple[Dict, float]]:\n",
    "        if self.index.ntotal == 0:\n",
    "            return []\n",
    "        \n",
    "        query_embedding = self.embedding_manager.encode([query])[0]\n",
    "        faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "        \n",
    "        k = min(k, self.index.ntotal)\n",
    "        distances, indices = self.index.search(query_embedding.reshape(1, -1), k)\n",
    "        \n",
    "        results = []\n",
    "        for idx, score in zip(indices[0], distances[0]):\n",
    "            if idx < len(self.movies):\n",
    "                results.append((self.movies[idx], float(score)))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save(self):\n",
    "        faiss.write_index(self.index, config.FAISS_INDEX_PATH)\n",
    "        with open(config.FAISS_MOVIES_PATH, 'wb') as f:\n",
    "            pickle.dump(self.movies, f)\n",
    "    \n",
    "    def load(self):\n",
    "        self.index = faiss.read_index(config.FAISS_INDEX_PATH)\n",
    "        with open(config.FAISS_MOVIES_PATH, 'rb') as f:\n",
    "            self.movies = pickle.load(f)\n",
    "\n",
    "# Initialize\n",
    "embedding_manager = EmbeddingManager(config.EMBEDDING_MODEL)\n",
    "vector_store = FAISSVectorStore(embedding_manager)\n",
    "print(\"‚úÖ Vector store initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4bc26",
   "metadata": {},
   "source": [
    "## 7. BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self):\n",
    "        self.bm25 = None\n",
    "        self.movies = []\n",
    "        self.tokenized_corpus = []\n",
    "    \n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        text = text.lower()\n",
    "        tokens = re.findall(r'\\w+', text)\n",
    "        return tokens\n",
    "    \n",
    "    def _create_movie_text(self, movie: Dict) -> str:\n",
    "        components = []\n",
    "        if movie.get(\"title\"):\n",
    "            components.append(movie[\"title\"])\n",
    "        \n",
    "        genres = movie.get(\"genres\", [])\n",
    "        genre_names = [g.get(\"name\", g) if isinstance(g, dict) else str(g) for g in genres]\n",
    "        components.extend(genre_names)\n",
    "        \n",
    "        if movie.get(\"overview\"):\n",
    "            components.append(movie[\"overview\"])\n",
    "        \n",
    "        return \" \".join(components)\n",
    "    \n",
    "    def add_movies(self, new_movies: List[Dict]):\n",
    "        self.movies.extend(new_movies)\n",
    "        \n",
    "        for movie in new_movies:\n",
    "            text = self._create_movie_text(movie)\n",
    "            tokens = self._tokenize(text)\n",
    "            self.tokenized_corpus.append(tokens)\n",
    "        \n",
    "        if self.tokenized_corpus:\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "    \n",
    "    def search(self, query: str, k: int = 20) -> List[Tuple[Dict, float]]:\n",
    "        if not self.bm25:\n",
    "            return []\n",
    "        \n",
    "        tokenized_query = self._tokenize(query)\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        top_indices = scores.argsort()[-k:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            if scores[idx] > 0:\n",
    "                results.append((self.movies[idx], float(scores[idx])))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save(self):\n",
    "        with open(config.BM25_INDEX_PATH, 'wb') as f:\n",
    "            pickle.dump({'bm25': self.bm25, 'movies': self.movies, 'corpus': self.tokenized_corpus}, f)\n",
    "    \n",
    "    def load(self):\n",
    "        with open(config.BM25_INDEX_PATH, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.bm25 = data['bm25']\n",
    "            self.movies = data['movies']\n",
    "            self.tokenized_corpus = data['corpus']\n",
    "\n",
    "bm25_retriever = BM25Retriever()\n",
    "print(\"‚úÖ BM25 retriever initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24c5c3",
   "metadata": {},
   "source": [
    "## 8. LLM-Powered Query Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import json\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    temperature=0,\n",
    "    google_api_key=config.GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "def analyze_query(query: str) -> Dict:\n",
    "    \"\"\"Use Gemini to analyze query for intent, mood, themes, keywords.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this movie recommendation query and extract ALL relevant information:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Extract and return a JSON object with:\n",
    "{{\n",
    "  \"intent\": \"exploration|similar_to|mood_based|comparison|direct_match\",\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"genres\": [\"genre1\", \"genre2\"],\n",
    "  \"mood\": \"overall emotional tone (e.g., dark, uplifting, tense, nostalgic)\",\n",
    "  \"themes\": [\"theme1\", \"theme2\"] (e.g., war, revenge, family, identity),\n",
    "  \"keywords\": [\"keyword1\", \"keyword2\"] (important concepts),\n",
    "  \"mentioned_movies\": [\"movie1\"] (if any specific movies mentioned),\n",
    "  \"mentioned_people\": [\"person1\"] (actors/directors if mentioned),\n",
    "  \"era_preference\": \"decade or time period if mentioned\",\n",
    "  \"rating_preference\": \"high|medium|any\",\n",
    "  \"specific_requirements\": \"any other specific needs\"\n",
    "}}\n",
    "\n",
    "Return ONLY the JSON, no other text.\"\"\"\n",
    "\n",
    "    try:\n",
    "        print(f\"  üß† Analyzing query with Gemini...\")\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        content = response.content\n",
    "        if \"```json\" in content:\n",
    "            content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in content:\n",
    "            content = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        \n",
    "        analysis = json.loads(content)\n",
    "        print(f\"  ‚úì Intent: {analysis.get('intent')}, Mood: {analysis.get('mood')}\")\n",
    "        print(f\"  ‚úì Themes: {analysis.get('themes')}\")\n",
    "        \n",
    "        return analysis\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† LLM analysis failed: {e}\")\n",
    "        return {\n",
    "            \"intent\": \"exploration\",\n",
    "            \"confidence\": 0.5,\n",
    "            \"genres\": [],\n",
    "            \"mood\": \"unknown\",\n",
    "            \"themes\": [],\n",
    "            \"keywords\": query.lower().split()\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LLM query analyzer ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8bf151",
   "metadata": {},
   "source": [
    "## 9. Intelligent TMDb Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intelligent_tmdb_search(\n",
    "    query: str,\n",
    "    genres: List[str] = None,\n",
    "    themes: List[str] = None,\n",
    "    mood: str = None,\n",
    "    keywords: List[str] = None,\n",
    "    max_results: int = 30\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Multi-strategy TMDb search using LLM analysis.\"\"\"\n",
    "    \n",
    "    all_movies = {}\n",
    "    \n",
    "    print(f\"üîç Intelligent TMDb Search:\")\n",
    "    print(f\"  Query: '{query}'\")\n",
    "    print(f\"  Themes: {themes}, Mood: {mood}\")\n",
    "    \n",
    "    # Strategy 1: Search ORIGINAL query first (most important!)\n",
    "    print(f\"  ‚Üí Strategy 1: /search original '{query}'\")\n",
    "    orig_results = tmdb_client.search_movies(query)\n",
    "    for movie in orig_results.get(\"results\", [])[:30]:\n",
    "        all_movies[movie.get(\"id\")] = movie\n",
    "    print(f\"    ‚úì Found {len(orig_results.get('results', []))} movies\")\n",
    "    \n",
    "    # Strategy 2: Search individual keywords\n",
    "    if keywords:\n",
    "        stop_words = {'a', 'an', 'the', 'of', 'in', 'on', 'at', 'to', 'for', 'and', 'or', 'but', 'me', 'about', 'like'}\n",
    "        important_keywords = [k for k in keywords if k.lower() not in stop_words]\n",
    "        \n",
    "        for keyword in important_keywords[:5]:  # Top 5 keywords\n",
    "            print(f\"  ‚Üí Strategy 2: /search keyword '{keyword}'\")\n",
    "            kw_results = tmdb_client.search_movies(keyword)\n",
    "            for movie in kw_results.get(\"results\", [])[:15]:\n",
    "                if movie.get(\"id\") not in all_movies:\n",
    "                    all_movies[movie.get(\"id\")] = movie\n",
    "            print(f\"    ‚úì Found {len(kw_results.get('results', []))} movies\")\n",
    "    \n",
    "    # Strategy 3: /discover with genre filters (if genres found)\n",
    "    if genres and len(all_movies) < 20:\n",
    "        print(f\"  ‚Üí Strategy 3: /discover with genres\")\n",
    "        genre_map = {g[\"name\"].lower(): g[\"id\"] for g in tmdb_client.get_genres().get(\"genres\", [])}\n",
    "        genre_ids = [str(genre_map.get(g.lower())) for g in genres if g.lower() in genre_map]\n",
    "        \n",
    "        if genre_ids:\n",
    "            result = tmdb_client.discover_movies(\n",
    "                with_genres=\",\".join(genre_ids),\n",
    "                sort_by=\"popularity.desc\"\n",
    "            )\n",
    "            for movie in result.get(\"results\", [])[:20]:\n",
    "                if movie.get(\"id\") not in all_movies:\n",
    "                    all_movies[movie.get(\"id\")] = movie\n",
    "            print(f\"    ‚úì Found {len(result.get('results', []))} movies\")\n",
    "    \n",
    "    # Strategy 4: Fallback - search just key themes\n",
    "    if len(all_movies) < 10 and themes:\n",
    "        for theme in themes[:3]:\n",
    "            print(f\"  ‚Üí Strategy 4: /search theme '{theme}'\")\n",
    "            theme_results = tmdb_client.search_movies(theme)\n",
    "            for movie in theme_results.get(\"results\", [])[:10]:\n",
    "                if movie.get(\"id\") not in all_movies:\n",
    "                    all_movies[movie.get(\"id\")] = movie\n",
    "            print(f\"    ‚úì Found {len(theme_results.get('results', []))} movies\")\n",
    "    \n",
    "    print(f\"üìä Total unique movies: {len(all_movies)}\")\n",
    "    \n",
    "    return sorted(all_movies.values(), key=lambda x: x.get(\"popularity\", 0), reverse=True)[:max_results]\n",
    "\n",
    "print(\"‚úÖ Intelligent search ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8518ae02",
   "metadata": {},
   "source": [
    "## 10. Re-Ranker with Keyword Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa73bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_keyword_match(movie: Dict, query: str) -> float:\n",
    "    \"\"\"Calculate keyword matching bonus.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    query_words = set(query_lower.split())\n",
    "    \n",
    "    stop_words = {'a', 'an', 'the', 'of', 'in', 'on', 'at', 'to', 'for', 'and', 'or', 'but', 'me', 'about'}\n",
    "    query_keywords = query_words - stop_words\n",
    "    \n",
    "    if not query_keywords:\n",
    "        return 0.0\n",
    "    \n",
    "    score = 0.0\n",
    "    \n",
    "    # Title matches\n",
    "    title = (movie.get(\"title\") or \"\").lower()\n",
    "    title_words = set(title.split())\n",
    "    title_matches = len(query_keywords & title_words)\n",
    "    score += (title_matches / len(query_keywords)) * 0.6\n",
    "    \n",
    "    # Overview matches\n",
    "    overview = (movie.get(\"overview\") or \"\").lower()\n",
    "    overview_words = set(overview.split())\n",
    "    overview_matches = len(query_keywords & overview_words)\n",
    "    score += (overview_matches / len(query_keywords)) * 0.4\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "def rerank_movies(\n",
    "    results: List[Tuple[Dict, float]],\n",
    "    query: str,\n",
    "    max_results: int = 10\n",
    ") -> List[Tuple[Dict, float]]:\n",
    "    \"\"\"Re-rank with composite scoring.\"\"\"\n",
    "    \n",
    "    reranked = []\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    for movie, initial_score in results:\n",
    "        # Semantic similarity\n",
    "        semantic_score = initial_score\n",
    "        \n",
    "        # Rating (normalized)\n",
    "        rating_score = min(movie.get(\"vote_average\", 0) / 10.0, 1.0)\n",
    "        \n",
    "        # Recency boost\n",
    "        release_date = movie.get(\"release_date\", \"\")\n",
    "        try:\n",
    "            release_year = int(release_date.split(\"-\")[0]) if release_date else 2000\n",
    "            age = current_year - release_year\n",
    "            recency_score = min(np.exp(-age / 10.0), 1.0)\n",
    "        except:\n",
    "            recency_score = 0.0\n",
    "        \n",
    "        # Popularity (log-normalized)\n",
    "        popularity = movie.get(\"popularity\", 0)\n",
    "        popularity_score = min(np.log10(popularity + 1) / 3.0, 1.0)\n",
    "        \n",
    "        # Keyword matching\n",
    "        keyword_score = calculate_keyword_match(movie, query)\n",
    "        \n",
    "        # Composite score\n",
    "        composite = (\n",
    "            0.25 * semantic_score +\n",
    "            0.20 * rating_score +\n",
    "            0.15 * recency_score +\n",
    "            0.10 * popularity_score +\n",
    "            0.30 * keyword_score  # High weight for keyword matching!\n",
    "        )\n",
    "        \n",
    "        reranked.append((movie, composite))\n",
    "    \n",
    "    reranked.sort(key=lambda x: x[1], reverse=True)\n",
    "    return reranked[:max_results]\n",
    "\n",
    "print(\"‚úÖ Re-ranker ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a01375",
   "metadata": {},
   "source": [
    "## 11. Main Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(query: str, top_k: int = 5):\n",
    "    \"\"\"Get movie recommendations.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Query: {query}\\n\")\n",
    "    \n",
    "    # 1. Analyze query with LLM\n",
    "    analysis = analyze_query(query)\n",
    "    \n",
    "    # 2. Hybrid retrieval from local database\n",
    "    print(\"\\n  ‚Üí Hybrid retrieval (Vector + BM25)...\")\n",
    "    vector_results = vector_store.search(query, k=50)\n",
    "    bm25_results = bm25_retriever.search(query, k=50)\n",
    "    print(f\"    ‚úì Vector: {len(vector_results)}, BM25: {len(bm25_results)}\")\n",
    "    \n",
    "    # Combine results\n",
    "    all_results = {}\n",
    "    for movie, score in vector_results:\n",
    "        all_results[movie.get(\"id\")] = (movie, score)\n",
    "    for movie, score in bm25_results:\n",
    "        movie_id = movie.get(\"id\")\n",
    "        if movie_id not in all_results:\n",
    "            all_results[movie_id] = (movie, score * 0.5)  # Lower weight for BM25 only\n",
    "    \n",
    "    # 3. Intelligent TMDb search\n",
    "    print(\"\\n  ‚Üí Intelligent TMDb API search...\")\n",
    "    tmdb_results = intelligent_tmdb_search(\n",
    "        query=query,\n",
    "        genres=analysis.get(\"genres\", []),\n",
    "        themes=analysis.get(\"themes\", []),\n",
    "        mood=analysis.get(\"mood\"),\n",
    "        keywords=analysis.get(\"keywords\", []),\n",
    "        max_results=30\n",
    "    )\n",
    "    \n",
    "    # Add TMDb results\n",
    "    for movie in tmdb_results:\n",
    "        movie_id = movie.get(\"id\")\n",
    "        if movie_id not in all_results:\n",
    "            all_results[movie_id] = (movie, 0.7)\n",
    "    \n",
    "    print(f\"\\nüìä Total unique movies: {len(all_results)}\")\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"\\n‚ùå No movies found!\")\n",
    "        return []\n",
    "    \n",
    "    # 4. Re-rank\n",
    "    print(\"  ‚Üí Re-ranking...\")\n",
    "    candidates = list(all_results.values())\n",
    "    reranked = rerank_movies(candidates, query, max_results=top_k)\n",
    "    \n",
    "    # 5. Save new movies to database\n",
    "    new_movies = [movie for movie, _ in reranked]\n",
    "    for movie in new_movies:\n",
    "        vector_store.add_movie(movie)\n",
    "    bm25_retriever.add_movies(new_movies)\n",
    "    \n",
    "    vector_store.save()\n",
    "    bm25_retriever.save()\n",
    "    print(f\"  üíæ Saved {len(new_movies)} movies to database\")\n",
    "    \n",
    "    return reranked\n",
    "\n",
    "print(\"‚úÖ Main recommendation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b046e28",
   "metadata": {},
   "source": [
    "## 12. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf089bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(results: List[Tuple[Dict, float]]):\n",
    "    \"\"\"Display recommendations nicely.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üé¨ MOVIE RECOMMENDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"\\nNo recommendations found.\")\n",
    "        return\n",
    "    \n",
    "    for i, (movie, score) in enumerate(results, 1):\n",
    "        title = movie.get(\"title\", \"Unknown\")\n",
    "        year = movie.get(\"release_date\", \"N/A\")[:4] if movie.get(\"release_date\") else \"N/A\"\n",
    "        rating = movie.get(\"vote_average\", 0)\n",
    "        \n",
    "        genres = movie.get(\"genres\", [])\n",
    "        if genres:\n",
    "            if isinstance(genres[0], dict):\n",
    "                genre_names = [g.get(\"name\", \"\") for g in genres]\n",
    "            else:\n",
    "                genre_names = genres\n",
    "            genre_str = \", \".join(genre_names)\n",
    "        else:\n",
    "            genre_str = \"N/A\"\n",
    "        \n",
    "        overview = movie.get(\"overview\", \"No overview available.\")[:200] + \"...\"\n",
    "        \n",
    "        print(f\"\\n{i}. {title} ({year})\")\n",
    "        print(f\"   ‚≠ê Rating: {rating:.1f}/10 | Match: {score:.1%}\")\n",
    "        print(f\"   üé≠ Genres: {genre_str}\")\n",
    "        print(f\"   üìù {overview}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(\"‚úÖ Display function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4690ad8",
   "metadata": {},
   "source": [
    "## 13. üé¨ Try It Out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: War movies about Indian soldiers\n",
    "query = \"Recommend me a war movie about indian soldiers\"\n",
    "results = get_recommendations(query, top_k=5)\n",
    "display_recommendations(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Sci-fi thrillers\n",
    "query = \"Dark sci-fi thriller like Blade Runner\"\n",
    "results = get_recommendations(query, top_k=5)\n",
    "display_recommendations(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69209334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Your custom query\n",
    "query = input(\"Enter your movie query: \")\n",
    "results = get_recommendations(query, top_k=5)\n",
    "display_recommendations(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d674da8",
   "metadata": {},
   "source": [
    "## 14. Check Database Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üìä Database Statistics:\")\n",
    "print(f\"  Vector Store: {vector_store.index.ntotal} movies\")\n",
    "print(f\"  BM25 Index: {len(bm25_retriever.movies)} movies\")\n",
    "print(f\"\\nüí° The database grows with each query!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
